{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:31:03.273908Z",
     "start_time": "2020-10-25T17:31:03.262197Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_table('../data/onet_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:31:03.606517Z",
     "start_time": "2020-10-25T17:31:03.562238Z"
    }
   },
   "outputs": [],
   "source": [
    "def intround(n: int, sigfigs: int) -> int:\n",
    "    n = str(n)\n",
    "    return n[:sigfigs] + ('0' * (len(n)-(sigfigs)))\n",
    "\n",
    "\n",
    "def adjust_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    data = data.drop('Shown in My Next Move', axis=1)\n",
    "    data = data.rename(columns={'O*NET-SOC Code':'soc_code', 'Reported Job Title': 'job_title'})\n",
    "    \n",
    "    # break down soc codes to usefull pieces\n",
    "    # https://www.bls.gov/soc/2018/soc_2018_class_and_coding_structure.pdf\n",
    "    data['soc_code_split'] = data['soc_code'].str.split('-')\n",
    "    data['major_group'] = data['soc_code_split'].apply(lambda x: int(x[0]))\n",
    "    data['occ_number'] = data['soc_code_split'].apply(lambda x: int(float(x[1])))\n",
    "    data['minor_group'] = data['soc_code_split'].apply(lambda x: intround(int(float(x[1])), 1))\n",
    "    \n",
    "    # mapping provided from above pdf\n",
    "    data['high_level_groups'] = data.major_group.map({\n",
    "        11: 1, 12:1, 13:1,\n",
    "        15:2, 16:2, 17:2, 18:2, 19:2,\n",
    "        21:3, 22:3, 23:3, 24:3, 25:3, 26:3, 27:3,\n",
    "        29:4,\n",
    "        31:5, 32:5, 33:5, 34:5, 35:5, 36:5, 37:5, 38:5, 39:5,\n",
    "        41:6,\n",
    "        43:7,\n",
    "        45:8,\n",
    "        47:9,\n",
    "        49:10,\n",
    "        51:11,\n",
    "        53:12,\n",
    "        55:13})\n",
    "    return data\n",
    "\n",
    "data = adjust_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:31:23.167790Z",
     "start_time": "2020-10-25T17:31:23.154600Z"
    }
   },
   "outputs": [],
   "source": [
    "job_titles = pd.read_table('../data/onet_job_titles.txt')\n",
    "job_titles = job_titles.drop('Description', axis=1)\n",
    "job_titles = job_titles.rename(columns={'O*NET-SOC Code':'soc_code', 'Title': 'soc_title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T19:00:21.662185Z",
     "start_time": "2020-10-25T19:00:21.648320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.major_group.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:31:23.685243Z",
     "start_time": "2020-10-25T17:31:23.675915Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.merge(data, job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T16:23:18.340166Z",
     "start_time": "2020-10-25T16:22:10.642327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chartnett/.local/share/virtualenvs/SOC_classifier-CmZmI2qY/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 1 is smaller than n_iter=45. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:   55.7s remaining:   55.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   56.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "def get_random_grid(default=False):\n",
    "    return {\n",
    "        \"n_estimators\": [1200],\n",
    "        \"min_samples_split\": [5],\n",
    "        \"min_samples_leaf\": [1],\n",
    "        \"max_features\": [\"sqrt\"],\n",
    "        \"max_depth\": [30],\n",
    "    }\n",
    "\n",
    "classifier = RandomizedSearchCV(\n",
    "                estimator=RandomForestClassifier(random_state=42),\n",
    "                param_distributions=get_random_grid(),\n",
    "                n_iter=45,\n",
    "                cv=10,\n",
    "                verbose=2,\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer=\"word\", stop_words=\"english\", strip_accents=\"ascii\", ngram_range=(1,2))\n",
    "vecotrized_string = vectorizer.fit_transform(data['job_title'])\n",
    "classifier.fit(vecotrized_string, data['high_level_agg_groups'])\n",
    "probability = classifier.predict_proba(vecotrized_string)\n",
    "\n",
    "\n",
    "prediction = [classifier.classes_[np.where(x == max(x))][0] for x in probability]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:39:11.389467Z",
     "start_time": "2020-10-25T17:38:26.592326Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chartnett/.local/share/virtualenvs/SOC_classifier-CmZmI2qY/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 1 is smaller than n_iter=45. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:   34.9s remaining:   34.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   35.3s finished\n"
     ]
    }
   ],
   "source": [
    "def tfidf_random_forest_classifier(data, X_var, Y_var):\n",
    "    vectorizer = TfidfVectorizer(analyzer=\"word\", stop_words=\"english\", strip_accents=\"ascii\")\n",
    "    vecotrized_string = vectorizer.fit_transform(data[X_var])\n",
    "    classifier.fit(vecotrized_string, data[Y_var])\n",
    "    probability = classifier.predict_proba(vecotrized_string)\n",
    "    prediction = [classifier.classes_[np.where(x == max(x))][0] for x in probability]\n",
    "    return vectorizer, classifier, prediction\n",
    "\n",
    "vectorizer, model, prediction = tfidf_random_forest_classifier(data, 'job_title', 'major_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:48:31.365690Z",
     "start_time": "2020-10-25T17:48:31.360550Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "def get_random_grid(default=False):\n",
    "    return {\n",
    "        \"n_estimators\": [300, 1200],\n",
    "        \"min_samples_split\": [3, 15],\n",
    "        \"min_samples_leaf\": [1],\n",
    "        \"max_features\": [\"sqrt\"],\n",
    "        \"max_depth\": [25, 100],\n",
    "    }\n",
    "\n",
    "\n",
    "def create_pipeline():\n",
    "    vectorizer = TfidfVectorizer(analyzer=\"word\", stop_words=\"english\", strip_accents=\"ascii\")\n",
    "    classifier = RandomizedSearchCV(\n",
    "        estimator=RandomForestClassifier(random_state=42),\n",
    "        param_distributions=get_random_grid(),\n",
    "        n_iter=45,\n",
    "        cv=10,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1)\n",
    "    pipe = Pipeline([('tfidf', vectorizer), ('random_forest', classifier)])\n",
    "    return pipe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:49:22.524017Z",
     "start_time": "2020-10-25T17:48:36.085498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chartnett/.local/share/virtualenvs/SOC_classifier-CmZmI2qY/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 1 is smaller than n_iter=45. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:   38.4s remaining:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   38.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(stop_words='english', strip_accents='ascii')),\n",
       "                ('random_forest',\n",
       "                 RandomizedSearchCV(cv=10,\n",
       "                                    estimator=RandomForestClassifier(random_state=42),\n",
       "                                    n_iter=45, n_jobs=-1,\n",
       "                                    param_distributions={'max_depth': [30],\n",
       "                                                         'max_features': ['sqrt'],\n",
       "                                                         'min_samples_leaf': [1],\n",
       "                                                         'min_samples_split': [5],\n",
       "                                                         'n_estimators': [1200]},\n",
       "                                    random_state=42, verbose=2))])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(data['job_title'], data['major_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:49:30.259430Z",
     "start_time": "2020-10-25T17:49:30.256685Z"
    }
   },
   "outputs": [],
   "source": [
    "t= pipe['random_forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T18:27:33.415839Z",
     "start_time": "2020-10-25T18:27:31.848029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 11, 11, ..., 51, 51, 51])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(data['job_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:49:55.316604Z",
     "start_time": "2020-10-25T17:49:55.309546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5457805670738541"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['major_group'] == prediction) / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T16:19:36.085901Z",
     "start_time": "2020-10-25T16:19:36.062030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>695</td>\n",
       "      <td>180</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1282</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>178</td>\n",
       "      <td>1017</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>168</td>\n",
       "      <td>24</td>\n",
       "      <td>596</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>237</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>72</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34</td>\n",
       "      <td>183</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>11</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>153</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>326</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>289</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>178</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3    4   5    6   7    8    9    10   11\n",
       "0   695   180    11    1   13   5    6   0    1    2    2    0\n",
       "1    48  1282    51    3    4   0    0   0    0    6   12    0\n",
       "2    20   178  1017    2    1   0    7   0    0    0   12    1\n",
       "3    18   168    24  596   14   0    2   0    0    0    0    0\n",
       "4    44   237    21    4  615   1    4   0    0    3   11    0\n",
       "5    33    72    16    0    4  89    9   0    0    0    1    0\n",
       "6    34   183    37    0   22   2  297   0    0    1   40    1\n",
       "7    18    89     2    0   11   0    0  10    2    0   34    2\n",
       "8     4   167     0    0    4   0    0   0  282   11   67    3\n",
       "9     4   153     3    2    4   0    0   0    9  326   11    0\n",
       "10    8   289     8    1    8   0    1   0    3    9  724    0\n",
       "11   18   178     5    1   19   0    3   0    2    2   87  176"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat = confusion_matrix(data['high_level_agg_groups'], prediction)\n",
    "pd.DataFrame(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T16:17:56.763887Z",
     "start_time": "2020-10-25T16:17:56.750368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 10,\n",
       " 'error_score': nan,\n",
       " 'estimator__bootstrap': True,\n",
       " 'estimator__ccp_alpha': 0.0,\n",
       " 'estimator__class_weight': None,\n",
       " 'estimator__criterion': 'gini',\n",
       " 'estimator__max_depth': None,\n",
       " 'estimator__max_features': 'auto',\n",
       " 'estimator__max_leaf_nodes': None,\n",
       " 'estimator__max_samples': None,\n",
       " 'estimator__min_impurity_decrease': 0.0,\n",
       " 'estimator__min_impurity_split': None,\n",
       " 'estimator__min_samples_leaf': 1,\n",
       " 'estimator__min_samples_split': 2,\n",
       " 'estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'estimator__n_estimators': 100,\n",
       " 'estimator__n_jobs': None,\n",
       " 'estimator__oob_score': False,\n",
       " 'estimator__random_state': 42,\n",
       " 'estimator__verbose': 0,\n",
       " 'estimator__warm_start': False,\n",
       " 'estimator': RandomForestClassifier(random_state=42),\n",
       " 'iid': 'deprecated',\n",
       " 'n_iter': 45,\n",
       " 'n_jobs': -1,\n",
       " 'param_distributions': {'n_estimators': [500],\n",
       "  'min_samples_split': [5],\n",
       "  'min_samples_leaf': [1],\n",
       "  'max_features': ['sqrt'],\n",
       "  'max_depth': [50]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'random_state': 42,\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 2}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
